{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "et56MYxQQz"
      },
      "source": [
        "# Compute Plate Feature Importances\n",
        "Created to prevent memory leakage while computing feature importances by calling this script from a bash script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Y8bvng6b1X"
      },
      "source": [
        "import argparse\n",
        "import pathlib\n",
        "import sys\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.append(str((pathlib.Path.cwd().parent / \"utils\").resolve(strict=True)))\n",
        "from isolation_forest_data_feature_importance import IsoforestFeatureImportance"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "mbC8XMq7Xk"
      },
      "source": [
        "# Inputs and Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "HhpE7AbC0a"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--anomaly_dataset_path\", type=str, required=True)\n",
        "parser.add_argument(\"--plate\", type=str, required=True)\n",
        "parser.add_argument(\"--morphology_dataset_path\", type=str, required=True)\n",
        "parser.add_argument(\"--model_path\", type=str, required=True)\n",
        "parser.add_argument(\"--feature_importances_output_path\", type=str, required=True)\n",
        "parser.add_argument(\"--plate_mapping_path\", type=str, required=True)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "anomaly_dataset = pathlib.Path(args.anomaly_dataset_path)\n",
        "morphology_dataset = pathlib.Path(args.morphology_dataset_path)\n",
        "model_path = pathlib.Path(args.model_path)\n",
        "feature_importances_output_path = pathlib.Path(args.feature_importances_output_path)\n",
        "plate_mapping_path = pathlib.Path(args.plate_mapping_path)\n",
        "anomalyze_model = joblib.load(model_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "CBWbimYhqp"
      },
      "source": [
        "# Compute Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "9YMWSXdoJn"
      },
      "source": [
        "# Number of samples to compute feature importances for in each category (anomalous or inlier)\n",
        "num_control_samples = 10\n",
        "num_anomalous_samples = 10\n",
        "\n",
        "merge_cols = [\n",
        "    \"Metadata_Plate\",\n",
        "    \"Metadata_Well\",\n",
        "    \"Metadata_Site\",\n",
        "    \"Metadata_ObjectNumber\",\n",
        "]\n",
        "\n",
        "plate_mappingdf = pd.read_csv(plate_mapping_path, sep=\"\\t\")[\n",
        "    [\"Assay_Plate_Barcode\", \"Perturbation\"]\n",
        "].rename(\n",
        "    columns={\n",
        "        \"Assay_Plate_Barcode\": \"Metadata_Plate\",\n",
        "        \"Perturbation\": \"Metadata_treatment_type\",\n",
        "    }\n",
        ")\n",
        "\n",
        "anomdf = pd.concat(\n",
        "    [pd.read_parquet(path) for path in anomaly_dataset.rglob(\"*.parquet\")],\n",
        "    ignore_index=True,\n",
        ")\n",
        "\n",
        "feature_importancesdf = []\n",
        "\n",
        "\n",
        "anomdf = anomdf.loc[anomdf[\"Metadata_Plate\"] == args.plate]\n",
        "\n",
        "for control_type in [\"negcon\", \"anomalous\"]:\n",
        "\n",
        "    # Negative controls shouldn't be anomalous and vice versa\n",
        "    if control_type == \"negcon\":\n",
        "        morphologydf = anomdf.loc[\n",
        "            (anomdf[\"Metadata_control_type\"] == \"negcon\")\n",
        "            & (anomdf[\"Metadata_Plate\"] == args.plate)\n",
        "        ].nlargest(num_control_samples, \"Result_anomaly_score\")\n",
        "\n",
        "    else:\n",
        "        morphologydf = anomdf.loc[\n",
        "            (anomdf[\"Metadata_control_type\"] != \"negcon\")\n",
        "            & (anomdf[\"Metadata_Plate\"] == args.plate)\n",
        "        ].nsmallest(num_anomalous_samples, \"Result_anomaly_score\")\n",
        "\n",
        "    platedf = pd.read_parquet(\n",
        "        list(morphology_dataset.rglob(f\"*{args.plate}*.parquet\"))[0]\n",
        "    )\n",
        "\n",
        "    platedf = platedf[merge_cols + anomalyze_model.feature_names_in_.tolist()]\n",
        "\n",
        "    morphologyonlydf = pd.merge(platedf, morphologydf, on=merge_cols, how=\"inner\")\n",
        "    morphologyonlydf = morphologyonlydf[anomalyze_model.feature_names_in_.tolist()]\n",
        "\n",
        "    result = IsoforestFeatureImportance(\n",
        "        estimators=anomalyze_model.estimators_,\n",
        "        morphology_data=morphologyonlydf,\n",
        "        num_train_samples_per_tree=anomalyze_model.max_samples_,\n",
        "    )()\n",
        "\n",
        "    result = result.assign(\n",
        "        Metadata_control_type=control_type,\n",
        "        Metadata_treatment_type=feature_importances_output_path.stem,\n",
        "        Metadata_Plate=args.plate,\n",
        "    )\n",
        "\n",
        "    feature_importancesdf.append(result)\n",
        "\n",
        "if feature_importancesdf:\n",
        "    pd.concat(feature_importancesdf, axis=0).to_parquet(\n",
        "        feature_importances_output_path / f\"{args.plate}.parquet\"\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}