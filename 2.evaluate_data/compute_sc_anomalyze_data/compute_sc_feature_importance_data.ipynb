{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "zkd21a2pL8"
      },
      "source": [
        "# Compute Sample Feature Importances\n",
        "This notebook computes feature importances by dataset, treatment type, and by anomaly score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "xvb69t4oBw"
      },
      "source": [
        "import pathlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "sys.path.append(str((pathlib.Path.cwd().parent / \"utils\").resolve(strict=True)))\n",
        "\n",
        "import joblib\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "KUHmTNEP3T"
      },
      "source": [
        "## Find the root of the git repo on the host system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "vdfNeby9lU"
      },
      "source": [
        "# Get the current working directory\n",
        "cwd = pathlib.Path.cwd()\n",
        "\n",
        "if (cwd / \".git\").is_dir():\n",
        "    root_dir = cwd\n",
        "\n",
        "else:\n",
        "    root_dir = None\n",
        "    for parent in cwd.parents:\n",
        "        if (parent / \".git\").is_dir():\n",
        "            root_dir = parent\n",
        "            break\n",
        "\n",
        "# Check if a Git root directory was found\n",
        "if root_dir is None:\n",
        "    raise FileNotFoundError(\"No Git root directory found.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "f2OGzBqBg7"
      },
      "source": [
        "# Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "FPf9gGwrq9"
      },
      "source": [
        "# Replace with your root folder path\n",
        "anomaly_datasets_path = (root_dir / \"big_drive/sc_anomaly_data\").resolve(strict=True)\n",
        "\n",
        "anomalyze_models_path = (root_dir / \"big_drive/isolation_forest_models\").resolve(\n",
        "    strict=True\n",
        ")\n",
        "\n",
        "plate_mapping_path = (\n",
        "    root_dir / \"reference_plate_data/experiment-metadata.tsv\"\n",
        ").resolve(strict=True)\n",
        "\n",
        "plate_mappingdf = pd.read_csv(plate_mapping_path, sep=\"\\t\")[\n",
        "    [\"Assay_Plate_Barcode\", \"Perturbation\"]\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "Pd6iLYYRnQ"
      },
      "source": [
        "# Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "VxPBfErVQM"
      },
      "source": [
        "feature_importances_path = root_dir / \"big_drive/sc_feature_importances\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "6QWRMmeVMb"
      },
      "source": [
        "# Sample and Compute Feature feature_importances\n",
        "Sample and then compute feature importances between the most anomalous and the least anomalous cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Eom828CFqT"
      },
      "source": [
        "model_suffix_name = \"_isolation_forest.joblib\"\n",
        "merge_cols = [\n",
        "    \"Metadata_Plate\",\n",
        "    \"Metadata_Well\",\n",
        "    \"Metadata_Site\",\n",
        "    \"Metadata_ObjectNumber\",\n",
        "]\n",
        "\n",
        "plate_mappingdf.rename(\n",
        "    columns={\n",
        "        \"Assay_Plate_Barcode\": \"Metadata_Plate\",\n",
        "        \"Perturbation\": \"Metadata_treatment_type\",\n",
        "    },\n",
        "    inplace=True,\n",
        ")\n",
        "\n",
        "for anomaly_dataset in anomaly_datasets_path.iterdir():\n",
        "\n",
        "    anomaly_model_name = anomaly_dataset.stem + model_suffix_name\n",
        "    morphology_dataset = root_dir / f\"big_drive/{anomaly_dataset.stem}\"\n",
        "    anomalyze_model = joblib.load(anomalyze_models_path / anomaly_model_name)\n",
        "\n",
        "    anomaly_paths = list(anomaly_dataset.rglob(\"*.parquet\"))\n",
        "\n",
        "    anomdf = pd.concat(\n",
        "        [pd.read_parquet(path) for path in anomaly_paths], ignore_index=True\n",
        "    )\n",
        "\n",
        "    anomdf = pd.merge(\n",
        "        left=anomdf, right=plate_mappingdf, on=\"Metadata_Plate\", how=\"inner\"\n",
        "    )\n",
        "\n",
        "    dataset_feature_importances_path = feature_importances_path / anomaly_dataset.stem\n",
        "\n",
        "    for treatment_type_name, treatment_typedf in anomdf.groupby(\n",
        "        \"Metadata_treatment_type\"\n",
        "    ):\n",
        "        treatment_feature_importances_path = (\n",
        "            dataset_feature_importances_path / treatment_type_name\n",
        "        )\n",
        "        treatment_feature_importances_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Morphology parquet files are separated by plate in each dataset\n",
        "        for plate in treatment_typedf[\"Metadata_Plate\"].unique():\n",
        "            subprocess.run(\n",
        "                [\n",
        "                    str(\"run_feature_importance.sh\"),\n",
        "                    str(anomaly_dataset),\n",
        "                    plate,\n",
        "                    str(morphology_dataset),\n",
        "                    str(anomalyze_models_path / anomaly_model_name),\n",
        "                    str(treatment_feature_importances_path),\n",
        "                    str(plate_mapping_path),\n",
        "                    str(\"compute_feature_importance_by_plate.py\"),\n",
        "                ]\n",
        "            )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1st loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n1st loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n1st loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n1st loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n2nd loop\n3rd loop\n3rd loop\n"
        }
      ],
      "execution_count": 1
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}