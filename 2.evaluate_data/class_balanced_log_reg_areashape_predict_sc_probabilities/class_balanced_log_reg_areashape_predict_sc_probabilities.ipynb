{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "EzUt4Twg5N"
      },
      "source": [
        "# Predict Single Cell Probabilities\n",
        "In this part of the analysis, the predicted single cell probabilities are stored in parquet files per plate.\n",
        "Predicted probabilities are generated from a weighted logistic regression trained on AreaShape features from the mitocheck morphology features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "OvtZf6TNyh"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "QuNHIYPoOl"
      },
      "source": [
        "import gzip\n",
        "import io\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import requests\n",
        "from joblib import load\n",
        "import sys"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "nerqgPEMEZ"
      },
      "source": [
        "## Find the path of the git directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "w2uAipPz4U"
      },
      "source": [
        "# Get the current working directory\n",
        "cwd = pathlib.Path.cwd()\n",
        "\n",
        "if (cwd / \".git\").is_dir():\n",
        "    root_dir = cwd\n",
        "\n",
        "else:\n",
        "    root_dir = None\n",
        "    for parent in cwd.parents:\n",
        "        if (parent / \".git\").is_dir():\n",
        "            root_dir = parent\n",
        "            break\n",
        "\n",
        "# Check if a Git root directory was found\n",
        "if root_dir is None:\n",
        "    raise FileNotFoundError(\"No Git root directory found.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "qykovcaCfD"
      },
      "source": [
        "## Load data code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "IRcafZmPA0"
      },
      "source": [
        "def load_joblib_from_url(url):\n",
        "    \"\"\"\n",
        "    Retirieve joblib or gzip csv file from url\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : url\n",
        "        The raw url of the file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    obj : any Python object\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    file_object = io.BytesIO(response.content)\n",
        "\n",
        "    if \".csv\" in url:\n",
        "        file_object = gzip.GzipFile(fileobj=file_object)\n",
        "        obj = pd.read_csv(file_object)\n",
        "\n",
        "    elif \".joblib\" in url:\n",
        "        obj = load(file_object)\n",
        "\n",
        "    return obj"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "j39BPjtiy5"
      },
      "source": [
        "# The path of the models used in the phenotypic_profiling_model repo\n",
        "model_path = \"https://github.com/WayScience/phenotypic_profiling_model/raw/main/2.train_model/models/multi_class_models\"\n",
        "\n",
        "# The path of the data used for the data used for inferencing in the phenotypic_profiling_model repo\n",
        "data_path = \"https://github.com/WayScience/phenotypic_profiling_model/raw/main/0.download_data/data/labeled_data.csv.gz\"\n",
        "\n",
        "# Path to the drive\n",
        "drive_path = f\"{root_dir}/big_drive\"\n",
        "\n",
        "# The predicted probabilities of the models on each cell from each plate\n",
        "output_proba_path = f\"{drive_path}/class_balanced_log_reg_probability_sc_data\"\n",
        "\n",
        "# The path of the normalized sc data\n",
        "norm_plate_path = sys.argv[1]\n",
        "\n",
        "# The path of the unnormalized sc data\n",
        "unnorm_plate_path = sys.argv[2]\n",
        "\n",
        "# Name of the plate\n",
        "plate_name = sys.argv[3]\n",
        "\n",
        "# The path of the model's predicted probabilities\n",
        "pathlib.Path(f\"{output_proba_path}\").mkdir(parents=True, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "O8TS0wIrg6"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "8nQDGIVMZe"
      },
      "source": [
        "# Store the models as a dictionary\n",
        "models = {\n",
        "    \"final\":\n",
        "        load_joblib_from_url(f\"{model_path}/final__CP_areashape_only__balanced.joblib\"),\n",
        "    \"shuffled\":\n",
        "        load_joblib_from_url(f\"{model_path}/shuffled_baseline__CP_areashape_only__balanced.joblib\")\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "nBtO1VsP0h"
      },
      "source": [
        "## Specify probability data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "S5i6VJ8mp1"
      },
      "source": [
        "# Original dataset used to select features for models\n",
        "data = load_joblib_from_url(data_path)\n",
        "\n",
        "# Extract CP features from all columns depending on desired dataset\n",
        "feature_cols = [col for col in data.columns if (\"CP__\" in col) and (\"AreaShape\" in col)]\n",
        "feature_cols = [string.replace(\"CP_\", \"Nuclei\") if \"CP\" in string else string for string in feature_cols]\n",
        "idx_feature_cols = pd.Index(feature_cols)\n",
        "\n",
        "# Metadata columns\n",
        "meta_cols = [\"Metadata_Well\", \"Metadata_Plate\", \"Metadata_ObjectNumber_cytoplasm\", \"Metadata_Site\"]\n",
        "\n",
        "# Location columns to keep in the final output\n",
        "loc_cols = [\"Nuclei_Location_Center_Y\", \"Nuclei_Location_Center_X\"]\n",
        "\n",
        "# Load the unnormalized plate data\n",
        "df_unnorm = pd.read_parquet(unnorm_plate_path)\n",
        "\n",
        "# Only retain metadata columns\n",
        "df_unnorm = df_unnorm[meta_cols]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "37Ji5sRSIq"
      },
      "source": [
        "## Save plate predicted probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "S4wolte6NK"
      },
      "source": [
        "# Load the dataframe for the plate\n",
        "df = pd.read_parquet(norm_plate_path)\n",
        "\n",
        "# Find columns that were in the original dataset used for inferencing, but not in the new dataset\n",
        "new_df_cols = idx_feature_cols.difference(df.columns).tolist()\n",
        "\n",
        "# Set the feature columns present in the new plate data to zero\n",
        "df[new_df_cols] = 0\n",
        "\n",
        "# Store the models\n",
        "modeldfs = []\n",
        "\n",
        "for model_type, model in models.items():\n",
        "    # Output dataframe (to be stored as an intermediate parquet file)\n",
        "    modeldf = pd.DataFrame(\n",
        "        model.predict_proba(df[feature_cols].values),\n",
        "        columns=model.classes_\n",
        "    )\n",
        "\n",
        "    # Store the type of model\n",
        "    modeldf[\"Metadata_model_type\"] = model_type\n",
        "\n",
        "    # Store the cytoplasm object number\n",
        "    modeldf[\"Metadata_ObjectNumber_cytoplasm\"] = df[\"Metadata_ObjectNumber_cytoplasm\"]\n",
        "\n",
        "    # Store the name of the plate\n",
        "    modeldf[\"Metadata_Plate\"] = df[\"Metadata_Plate\"]\n",
        "\n",
        "    # Store the name of the well\n",
        "    modeldf[\"Metadata_Well\"] = df[\"Metadata_Well\"]\n",
        "\n",
        "    # Store the name of the site\n",
        "    modeldf[\"Metadata_Site\"] = df[\"Metadata_Site\"]\n",
        "\n",
        "    # Add the nuclei locations (x,y)\n",
        "    modeldf = modeldf.merge(df_unnorm, how=\"inner\", on=meta_cols)\n",
        "\n",
        "    modeldfs.append(modeldf)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "siutlyKjrT"
      },
      "source": [
        "## Save model probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Ib8Cie0tft"
      },
      "source": [
        "modeldfs = pd.concat(modeldfs)\n",
        "\n",
        "# Save predictions in temporary location to free memory\n",
        "modeldfs.to_parquet(f\"{output_proba_path}/{plate_name}_class_balanced_log_reg_areashape_model_probabilities.parquet\", index=True)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}